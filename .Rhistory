library(RSelenium)
library(tidyverse)
library(rvest)
library(measurements)
library(geosphere)
library(leaflet)
library(RSelenium)
library(tidyverse)
library(rvest)
library(measurements)
library(geosphere)
library(leaflet)
#reads in the US Cities table
wiki <- read_html("https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population")
tbl1 <- wiki %>%
html_node(xpath ='//*[@id="mw-content-text"]/div/table[5]') %>%
html_table()
#outputs US City's and there general statistics
tbl1
#renmaes repeated column headings
colnames(tbl1)[7] = "2016 land area(miles)"
colnames(tbl1)[8] = "2016 land area(km)"
colnames(tbl1)[9] = "2016 pop density(miles)"
colnames(tbl1)[10] = "2016 pop density(km)"
#seperates Long/Lat column into 3 columns
tbl2 <- data.frame(str_split_fixed(tbl1$Location, " ", 3))
colnames(tbl2)[1] = "Latitude"
colnames(tbl2)[2] = "Longitude"
colnames(tbl2)[3] = "junk"
drop <- c("junk")
#drops column junk
tbl3 <- tbl2[ , !(names(tbl2) %in% drop)]
#merges original table with new Lat/Long table
tbl4 <- merge(tbl1, tbl3, by="row.names")
#repleaces incorrect formatting with black space
tbl4["City_clean"] <- str_replace(tbl4$City, "\\[.*\\]", "")
#orders tbl4 by rank
tbl5 <- tbl4[order(tbl4$`2018rank`),]
#grabs columns i need for scraping
tbl6 <- tbl5 %>%
select(City_clean, `State[c]`, Latitude, Longitude)
#View(tbl6)
df1 <- read.csv("~/data 900/uhaul.csv")
View(df1)
library(RSelenium)
library(tidyverse)
library(rvest)
library(measurements)
library(geosphere)
library(leaflet)
#reads in the US Cities table
wiki <- read_html("https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population")
tbl1 <- wiki %>%
html_node(xpath ='//*[@id="mw-content-text"]/div/table[5]') %>%
html_table()
#outputs US City's and there general statistics
tbl1
#renmaes repeated column headings
colnames(tbl1)[7] = "2016 land area(miles)"
colnames(tbl1)[8] = "2016 land area(km)"
colnames(tbl1)[9] = "2016 pop density(miles)"
colnames(tbl1)[10] = "2016 pop density(km)"
#seperates Long/Lat column into 3 columns
tbl2 <- data.frame(str_split_fixed(tbl1$Location, " ", 3))
colnames(tbl2)[1] = "Latitude"
colnames(tbl2)[2] = "Longitude"
colnames(tbl2)[3] = "junk"
drop <- c("junk")
#drops column junk
tbl3 <- tbl2[ , !(names(tbl2) %in% drop)]
#merges original table with new Lat/Long table
tbl4 <- merge(tbl1, tbl3, by="row.names")
#repleaces incorrect formatting with black space
tbl4["City_clean"] <- str_replace(tbl4$City, "\\[.*\\]", "")
#orders tbl4 by rank
tbl5 <- tbl4[order(tbl4$`2018rank`),]
#grabs columns i need for scraping
tbl6 <- tbl5 %>%
select(City_clean, `State[c]`, Latitude, Longitude)
#View(tbl6)
uhaul <- read.csv("~/data 900/uhaul.csv")
df1<- uhaul %>%
select(X, price, beg_city, beg_lat, beg_state,beg_long, end_city,end_state,end_lat, end_long)
View(df1)
df1 <- read.csv("~/data 900/uhaul.csv")
View(df1)
uhaul <- read.csv("C:/Users/eric_/OneDrive/Desktop/my_project/Web Scraping UHaul/uhaul.csv")
View(uhaul)
uhaul <- read.csv("C:/Users/eric_/OneDrive/Desktop/my_project/Web Scraping UHaul/uhaul.csv")
View(df1)
df1 <- read.csv("C:/Users/eric_/OneDrive/Desktop/my_project/Web Scraping UHaul/uhaul.csv")
View(df1)
#creates two tables for the beginning coordnates and end coordnates
df1$beg_long <- as.numeric(df1$beg_long)
df1$beg_lat <- as.numeric(df1$beg_lat)
df1$end_long <- as.numeric(df1$end_long)
df1$end_lat <- as.numeric(df1$end_lat)
df_beg <- select(df1,beg_long, beg_lat)
df_end <- select(df1, end_long, end_lat)
#df1$beg_long <- df1$beg_long*-1
#df1$end_long <- df1$end_long*-1
#finds the distance in meters between the two cities
df1$dist_meters <- distHaversine(df_beg, df_end)
#puts the distance into km
df1$dist_km <- df1$dist_meters/1000
View(df1)
#removes $ from the price column to put it into numeric format
df1$price <- as.numeric(gsub('[$,]', '', df1$price))
#divides distance/price for each row
df1$price_per_km <- df1$price/df1$dist_km
View(df1)
#mkes column of 1,1,2,2,3,3, etc
df1[['group']] <- rep(1:45, each=2)
View(df1)
#ordering the df by dist_km
df2 <- df1[order(df1$`dist_km`),]
#it creates a column path with alternating 1's and 2's
for(i in 1:90){
if((i %% 2) == 0){
df2[i,"Path"] = 2
}
else{df2[i,"Path"] = 1}}
View(df2)
list = c()
#finds the price difference between each two city pair
for(i in 1:90){
if((i %% 2) != 0){
df2[i,"diff"] = (df2$price_per_km[i] - df2$price_per_km[i+1])
}
else{df2[i,"diff"] = (df2$price_per_km[i] - df2$price_per_km[i-1])}}
view(df2)
#ordering the df by rank
df3 <- df2[order(df2$`diff`, decreasing = TRUE),]
for(i in 1:90){
df3[i,"rank"] = i
}
View(df3)
write_excel_csv(df3, "uhaul_final.csv")
